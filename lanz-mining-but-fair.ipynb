{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d31ae0c-ab1f-4f63-be05-2fdcc94fca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29faa9ce-1d06-4e1b-801f-9245eca1723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GastEintrag:\n",
    "    namen: List[str]      \n",
    "    beschreibung: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6822874b-1cf0-4781-966f-6ba42a91f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_list_from_pdf(pdf_path): \n",
    "    \n",
    "    reader = PdfReader(pdf_path)\n",
    "    episodes = []\n",
    "    current_episode_parts = []\n",
    "\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            matches = re.findall(r\"Seite\\s+(\\d+)\\s+von\\s+(\\d+)\", text)\n",
    "\n",
    "            if matches:\n",
    "                # Wir nehmen das letzte Vorkommen auf der Seite, da es sich meist um die Fußzeile handelt\n",
    "                current_page_num, total_pages = map(int, matches[-1])\n",
    "\n",
    "                if current_page_num == 1:\n",
    "                        # Neue Episode beginnt\n",
    "                        current_episode_parts = [text]\n",
    "                else:\n",
    "                    # Fortsetzung einer Episode\n",
    "                    current_episode_parts.append(text)\n",
    "\n",
    "                        \n",
    "                if current_page_num == total_pages:\n",
    "                    # Text zusammenfügen und zur Ergebnisliste hinzufügen\n",
    "                    full_text = \"\\n\".join(current_episode_parts)\n",
    "                    episodes.append(full_text)\n",
    "                    current_episode_parts = [] # Puffer zurücksetzen\n",
    "\n",
    "    return episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "362a3301-bf6d-4bbb-88bf-73f352318a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_files(episodes, path):\n",
    "    \"\"\"\n",
    "    Speichert die Liste der Episoden in eine einzelne Textdatei.\n",
    "    \n",
    "    Args:\n",
    "        episodes (list): Die Liste mit den Episodentexten.\n",
    "        filename (str): Der Name der Zieldatei.\n",
    "    \"\"\"\n",
    "    # 'utf-8' ist wichtig für Umlaute (ä, ö, ü) und Sonderzeichen\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, episode in enumerate(episodes, 1):\n",
    "            # Eine Überschrift pro Episode schreiben\n",
    "            f.write(f\"--- EPISODE {i} ---\\n\\n\")\n",
    "            \n",
    "            # Den eigentlichen Text schreiben\n",
    "            f.write(episode)\n",
    "            \n",
    "            # Trennlinie für bessere Lesbarkeit am Ende jeder Episode\n",
    "            f.write(\"\\n\\n\" + \"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "    print(f\"Erfolgreich gespeichert in: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa49db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_episodes(episodes):\n",
    "    cleaned_episodes = []\n",
    "\n",
    "    # Einfacher Schalter: Haben wir die Folge schon gesehen?\n",
    "    hatte_15_12_schon = False\n",
    "    hatte_12_11_schon = False \n",
    "\n",
    "    scheller_pattern = r\"Scheller,.*?ZDF P r o g r a m m - D a t e n b a n k\"\n",
    "    page_pattern = r\"TV Seite\\s+\\d+\\s+von\\s+\\d+\"\n",
    "\n",
    "    for text in episodes:\n",
    "        \n",
    "        # --- SPEZIAL-CHECK FÜR Duplikate ---\n",
    "        if \"Markus Lanz 15.12.2015\" in text:\n",
    "            if hatte_15_12_schon:\n",
    "                # Wenn wir sie schon einmal hatten (True), ist das hier das Duplikat -> Rauslöschen (continue)\n",
    "                print(\"Found Duplicate: Markus Lanz 15.12.2015\")\n",
    "                continue\n",
    "            else:\n",
    "                # Das erste Mal gefunden -> Schalter umlegen und behalten\n",
    "                hatte_15_12_schon = True\n",
    "\n",
    "\n",
    "        if \"Markus Lanz 12.11.2015\" in text: \n",
    "            if hatte_12_11_schon:\n",
    "                print(\"Found Duplicate: Markus Lanz 12.11.2015\")\n",
    "                # Wenn wir sie schon einmal hatten (True), ist das hier das Duplikat -> Rauslöschen (continue)\n",
    "                continue\n",
    "            else:\n",
    "                # Das erste Mal gefunden -> Schalter umlegen und behalten\n",
    "                hatte_12_11_schon = True\n",
    "\n",
    "\n",
    "        # 1. Den Scheller-Block entfernen\n",
    "        text = re.sub(scheller_pattern, \"\", text, flags=re.DOTALL | re.IGNORECASE)\n",
    "        \n",
    "        # 2. Die Seitenzahlen entfernen\n",
    "        text = re.sub(page_pattern, \"\", text, flags=re.IGNORECASE)\n",
    "        \n",
    "        # 3. Kosmetik\n",
    "        text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "        \n",
    "        cleaned_episodes.append(text.strip())\n",
    "        \n",
    "    return cleaned_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrahiere_sendungs_details(text: str) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Extrahiert Datum, Sendezeit-Range und Dauer aus dem rohen Textblock.\n",
    "    \"\"\"\n",
    "    daten = {\n",
    "        \"Titel\": None,\n",
    "        \"Datum\": None,\n",
    "        \"Sendezeit\": None,\n",
    "        \"Dauer\": None,\n",
    "        \"FolgenNr\": None,\n",
    "        \"Staffel\": None, \n",
    "        \"Folge\": None,\n",
    "        \"Information\": None\n",
    "    }\n",
    "\n",
    "    match_folgen_nr = re.search(r\"FolgenNr\\s+(\\d+)\", text)\n",
    "    if match_folgen_nr:\n",
    "        daten[\"FolgenNr\"] = match_folgen_nr.group(1)\n",
    "    else: \n",
    "        daten[\"FolgenNr\"] = None\n",
    "\n",
    "    match_staffel = re.search(r\"Staffel\\s+(\\d+)\", text)\n",
    "    if match_staffel:\n",
    "        daten[\"Staffel\"] = match_staffel.group(1)\n",
    "    else:\n",
    "        daten[\"Staffel\"] = None\n",
    "\n",
    "    match_folge = re.search(r\"Folge\\s+(\\d+)\", text)\n",
    "    if match_folge:\n",
    "        daten[\"Folge\"] = match_folge.group(1)\n",
    "    else:\n",
    "        daten[\"Folge\"] = None\n",
    "\n",
    "\n",
    "    # 1. Datum suchen (Nach dem Keyword \"Publikation\")\n",
    "    if \"Publikation\" in text:\n",
    "        # Wir nehmen alles nach \"Publikation\"\n",
    "        part_publikation = text.split(\"Publikation\", 1)[1]\n",
    "        \n",
    "        # Regex für Datum (DD.MM.YYYY)\n",
    "        # Wir suchen das ERSTE Datum, das nach Publikation auftaucht\n",
    "        date_match = re.search(r\"(\\d{2}\\.\\d{2}\\.\\d{4})\", part_publikation)\n",
    "        if date_match:\n",
    "            daten[\"Datum\"] = date_match.group(1)\n",
    "\n",
    "    # 2. Sendezeit und Dauer suchen (Nach dem Keyword \"Sachinhalt\")\n",
    "    # Das Format ist dort meist: \"Sachinhalt HH:MM:SS - HH:MM:SS MMM'SS\"\n",
    "    if \"Sachinhalt\" in text:\n",
    "        part_sachinhalt = text.split(\"Sachinhalt\", 1)[1]\n",
    "        \n",
    "        # Regex Erklärung:\n",
    "        # (\\d{2}:\\d{2}:\\d{2}\\s*-\\s*\\d{2}:\\d{2}:\\d{2}) -> Gruppe 1: Zeit von - bis\n",
    "        # \\s+                                         -> Leerzeichen\n",
    "        # (\\d{2,3}'\\d{2})                             -> Gruppe 2: Dauer (z.B. 67'41 oder 067'41)\n",
    "        \n",
    "        zeit_pattern = r\"(\\d{2}:\\d{2}:\\d{2}\\s*-\\s*\\d{2}:\\d{2}:\\d{2})\\s+(\\d{2,3}'\\d{2})\"\n",
    "        \n",
    "        zeit_match = re.search(zeit_pattern, part_sachinhalt)\n",
    "        if zeit_match:\n",
    "            daten[\"Sendezeit\"] = zeit_match.group(1)\n",
    "            daten[\"Dauer\"] = zeit_match.group(2)\n",
    "\n",
    "    # Information zwischen \"Sachinhalt\" und \"Jugendeignung\" extrahieren\n",
    "    match = re.search(r\"Sachinhalt(.*?)Jugendeignung\", text, re.DOTALL)\n",
    "    if match:\n",
    "        daten[\"Information\"] = match.group(1).strip().replace(\"\\n\", \" \")\n",
    "\n",
    "    #Titel extrahieren\n",
    "    keyword = 'Sendetitel'\n",
    "\n",
    "    if keyword not in text:\n",
    "        daten[\"titel\"] = \"Unbekannt (Kein 'Sendetitel' gefunden)\"\n",
    "\n",
    "    parts = text.split(keyword, 1)\n",
    "\n",
    "    # 3. Prüfen, ob der Split erfolgreich war (Liste muss mind. 2 Teile haben)\n",
    "    if len(parts) < 2:\n",
    "        daten[\"titel\"] =  \"Unbekannt (Split fehlgeschlagen)\"\n",
    "\n",
    "    raw_title_part = parts[1]\n",
    "\n",
    "    title = raw_title_part.split('\\n', 1)[0]\n",
    "\n",
    "    daten[\"Titel\"] = title \n",
    "\n",
    "    return daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_guests(text: str) -> List[GastEintrag]:\n",
    "    ergebnisse = []\n",
    "\n",
    "\n",
    "    keywords = [\"Studiogästen\", \"Studiogast\"]\n",
    "    \n",
    "    relevant_part = text  # Fallback: Ganzer Text, falls kein Keyword gefunden wird\n",
    "\n",
    "    for kw in keywords:\n",
    "        if kw in text:\n",
    "            # Wir splitten beim ersten gefundenen Keyword und nehmen den Teil danach\n",
    "            relevant_part = text.split(kw, 1)[1]\n",
    "\n",
    "    blöcke = re.finditer(r'([^)]+)\\(([^)]+)\\)', relevant_part)\n",
    "\n",
    "    for match in blöcke:\n",
    "        namen_roh = match.group(1).strip()\n",
    "        beschreibung = match.group(2).strip()\n",
    "        \n",
    "        # Wir ignorieren Satzzeichen am Ende des Namensblocks (z.B. Kommas vom vorherigen Eintrag)\n",
    "        if namen_roh.startswith(\",\"):\n",
    "            namen_roh = namen_roh[1:].strip()\n",
    "\n",
    "        # Namen aus dem Roh-String extrahieren\n",
    "        # Muster: Wort (TitleCase) + optional Mittelname/Initial + WORT (UPPERCASE)\n",
    "        # \\b           -> Wortgrenze\n",
    "        # [A-ZÄÖÜ][a-zäöü]+ -> Vorname (Großbuchstabe gefolgt von Kleinbuchstaben)\n",
    "        # (?: ... )* -> Optionale Mittelnamen oder Initialen (z.B. \"Philip D\" oder \"Hans Peter\")\n",
    "        # \\s+          -> Leerzeichen\n",
    "        # [A-ZÄÖÜß]+   -> NACHNAME (Nur Großbuchstaben, mind. 2 Zeichen um \"I\" vs \"IN\" zu unterscheiden, oder einfach +)\n",
    "        \n",
    "        name_pattern = r'\\b[A-ZÄÖÜ][a-zäöü]+(?:\\s+(?:[A-Z]\\.?|[A-ZÄÖÜ][a-zäöü]+))*\\s+[A-ZÄÖÜß]+(?:-[A-ZÄÖÜß]+)?'\n",
    "        \n",
    "        gefundenen_namen = re.findall(name_pattern, namen_roh)\n",
    "\n",
    "        if gefundenen_namen:\n",
    "            eintrag = GastEintrag(\n",
    "                namen=gefundenen_namen,\n",
    "                beschreibung=beschreibung\n",
    "            )\n",
    "            ergebnisse.append(eintrag)\n",
    "\n",
    "    return ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1877fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_persons(episodes):\n",
    "    \"\"\"\n",
    "    Extrahiert Gäste und gruppiert sie pro Person.\n",
    "    Ausgabe: Eine Zeile pro Gast.\n",
    "    - Alle Beschreibungen werden gesammelt und kommagetrennt.\n",
    "    - Alle Auftritte werden als eigene Spalten angefügt.\n",
    "    \"\"\"\n",
    "\n",
    "    guest_map = {}\n",
    "\n",
    "    for episode_text in episodes:\n",
    "        if not episode_text:\n",
    "            continue\n",
    "\n",
    "        # 1. Daten extrahieren\n",
    "        daten = extrahiere_sendungs_details(episode_text)\n",
    "\n",
    "        if \"Sachinhalt\" not in episode_text:\n",
    "            continue\n",
    "\n",
    "        text_flat = episode_text.replace('\\n', ' ').replace('\\r', '')\n",
    "\n",
    "        try:\n",
    "            content_part = text_flat.split(\"Sachinhalt\", 1)[1]\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "        # Keywords zum Abschneiden\n",
    "        keywords = [';', 'über', 'Themen', 'Thema', 'Themen:', 'Thema:', 'Jugendeignung', 'Schwerpunktthemen:', 'Schwerpunktthemen', 'Scherpunktthemen:']\n",
    "        keywords.sort(key=len, reverse=True)\n",
    "        pattern_split = \"|\".join(map(re.escape, keywords))\n",
    "        \n",
    "        guests_section = re.split(pattern_split, content_part, maxsplit=1)[0]\n",
    "\n",
    "        # Regex ausführen\n",
    "        gefundene_eintraege = extract_guests(guests_section)\n",
    "        \n",
    "        # Auftritt-String formatieren\n",
    "        auftritt_string = daten['Titel']\n",
    "        \n",
    "        # Datum parsen\n",
    "        try:\n",
    "            datum_sort = pd.to_datetime(daten[\"Datum\"], format=\"%d.%m.%Y\", errors=\"coerce\")\n",
    "        except:\n",
    "            datum_sort = pd.NaT\n",
    "\n",
    "        for eintrag in gefundene_eintraege:\n",
    "            for einzelner_name in eintrag.namen:\n",
    "                name_clean = einzelner_name.strip()\n",
    "                \n",
    "                # Wenn Gast noch nicht bekannt, neu anlegen\n",
    "                if name_clean not in guest_map:\n",
    "                    guest_map[name_clean] = {\n",
    "                        \"descriptions\": set(), # Set für eindeutige Beschreibungen\n",
    "                        \"appearances\": [] \n",
    "                    }\n",
    "                \n",
    "                # Beschreibung hinzufügen (wenn vorhanden)\n",
    "                if eintrag.beschreibung:\n",
    "                    clean_desc = eintrag.beschreibung.strip()\n",
    "                    if clean_desc: # Nur nicht-leere Beschreibungen\n",
    "                        guest_map[name_clean][\"descriptions\"].add(clean_desc)\n",
    "\n",
    "                # Auftritt hinzufügen\n",
    "                guest_map[name_clean][\"appearances\"].append((datum_sort, auftritt_string))\n",
    "\n",
    "    # --- DATAFRAME ERSTELLEN ---\n",
    "    \n",
    "    final_rows = []\n",
    "    \n",
    "    for name, info in guest_map.items():\n",
    "        # 1. Auftritte sortieren\n",
    "        sorted_apps = sorted(info[\"appearances\"], key=lambda x: (x[0] is pd.NaT, x[0]))\n",
    "        app_strings = [app[1] for app in sorted_apps]\n",
    "        \n",
    "        # 2. Beschreibungen zusammenfügen\n",
    "        # Wir sortieren die Liste, damit die Reihenfolge deterministisch ist\n",
    "        # und joinen sie mit Komma und Leerzeichen\n",
    "        combined_description = \", \".join(sorted(list(info[\"descriptions\"])))\n",
    "        \n",
    "        row = {\n",
    "            \"Name\": name,\n",
    "            \"Beschreibung\": combined_description, # Alle Beschreibungen hier\n",
    "            \"Anzahl_Auftritte\": len(app_strings)\n",
    "        }\n",
    "        \n",
    "        # Dynamisch Spalten \"Public Appearance X\" füllen\n",
    "        for idx, app_str in enumerate(app_strings, start=1):\n",
    "            row[f\"Public Appearance {idx}\"] = app_str\n",
    "            \n",
    "        final_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(final_rows)\n",
    "\n",
    "    if not df.empty:\n",
    "        df = df.sort_values(by=\"Name\")\n",
    "        \n",
    "        # Spalten ordnen\n",
    "        cols = list(df.columns)\n",
    "        base_cols = [\"Name\", \"Beschreibung\", \"Anzahl_Auftritte\"]\n",
    "        appearance_cols = [c for c in cols if c.startswith(\"Public Appearance\")]\n",
    "        \n",
    "        # Appearance Spalten numerisch korrekt sortieren (1, 2, ... 10)\n",
    "        appearance_cols.sort(key=lambda x: int(x.split(\" \")[-1]))\n",
    "        \n",
    "        # Zusammenfügen, dabei sicherstellen, dass nur existierende Spalten genutzt werden\n",
    "        final_cols = base_cols + appearance_cols\n",
    "        # Falls durch das DataFrame erstellen noch andere Spalten entstanden wären (unwahrscheinlich), fliegen sie hier raus\n",
    "        df = df[final_cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e1366aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_episodes(episodes):\n",
    "    \"\"\"\n",
    "    Erstellt einen DataFrame mit einer Zeile pro Episode.\n",
    "    Enthält Metadaten, dynamische Spalten für Gäste und eine berechnete Season-Spalte.\n",
    "    \"\"\"\n",
    "\n",
    "    alle_daten = []\n",
    "\n",
    "    for episode_text in episodes:\n",
    "        if not episode_text or not episode_text.strip():\n",
    "            continue\n",
    "\n",
    "        daten = extrahiere_sendungs_details(episode_text)\n",
    "\n",
    "        if \"Sachinhalt\" not in episode_text:\n",
    "            continue\n",
    "\n",
    "        text_flat = episode_text.replace('\\n', ' ').replace('\\r', '')\n",
    "\n",
    "        try:\n",
    "            content_part = text_flat.split(\"Sachinhalt\", 1)[1]\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "        keywords = [';', 'über', 'Themen', 'Thema', 'Themen:', 'Thema:', 'Jugendeignung', 'Schwerpunktthemen:', 'Schwerpunktthemen', 'Scherpunktthemen:']\n",
    "        keywords.sort(key=len, reverse=True)\n",
    "        \n",
    "        pattern_split = \"|\".join(map(re.escape, keywords))\n",
    "        guests_section = re.split(pattern_split, content_part, maxsplit=1)[0]\n",
    "\n",
    "        gefundene_eintraege = extract_guests(guests_section)\n",
    "        \n",
    "        zeilen_daten = {\n",
    "            \"Sendungstitel\": daten.get(\"Titel\"),\n",
    "            \"Staffel\": daten.get(\"Staffel\"),\n",
    "            \"Folge\": daten.get(\"Folge\"),\n",
    "            \"FolgenNr\": daten.get(\"FolgenNr\"),\n",
    "            \"Publikationsdatum\": daten.get(\"Datum\"),\n",
    "            \"Dauer\": daten.get(\"Dauer\"),\n",
    "            \"Infos\": daten.get(\"Information\")\n",
    "        }\n",
    "        \n",
    "        gast_counter = 1\n",
    "        for eintrag in gefundene_eintraege:\n",
    "            for einzelner_name in eintrag.namen:\n",
    "                key = f\"Gast_{gast_counter}\"\n",
    "                zeilen_daten[key] = einzelner_name\n",
    "                gast_counter += 1\n",
    "\n",
    "        alle_daten.append(zeilen_daten)\n",
    "\n",
    "    # --- DataFrame erstellen ---\n",
    "    df = pd.DataFrame(alle_daten)\n",
    "\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Datums-Hilfsspalte erstellen (wichtig für Sortierung UND Staffel-Berechnung)\n",
    "    # Wir nutzen 'coerce', damit Fehler NaT ergeben, statt das Skript crashen zu lassen\n",
    "    df[\"Datum_Sortierbar\"] = pd.to_datetime(df[\"Publikationsdatum\"], format=\"%d.%m.%Y\", errors=\"coerce\")\n",
    "\n",
    "    # --- Logik für die \"season\" Spalte ---\n",
    "    def get_season_string(row):\n",
    "        existing_staffel = row.get(\"Staffel\")\n",
    "        titel = str(row.get(\"Sendungstitel\", \"\"))\n",
    "        datum_obj = row.get(\"Datum_Sortierbar\")\n",
    "\n",
    "        # Fall 1: Staffel ist bereits vorhanden\n",
    "        if pd.notna(existing_staffel) and str(existing_staffel).strip():\n",
    "            return f\"Markus Lanz, Staffel {existing_staffel}\"\n",
    "        \n",
    "        # Fall 2: Staffel fehlt -> Prüfen ob Titel das Standard-Format hat\n",
    "        # Regex prüft auf exakt \"Markus Lanz DD.MM.YYYY\" (D=Ziffer)\n",
    "        \n",
    "        if re.match(r\"^Markus Lanz \\d{2}\\.\\d{2}\\.\\d{4}$\", titel):\n",
    "            calc_staffel = datum_obj.year - 2007\n",
    "            return f\"Markus Lanz, Staffel {calc_staffel}\"\n",
    "                \n",
    "        # Fall 3: Weder Staffel vorhanden noch Titel-Format passend -> Leer\n",
    "        return \"\"\n",
    "\n",
    "    df['Sendungstitel'] = df['Sendungstitel'].str.strip()\n",
    "    # Die Funktion auf jede Zeile anwenden\n",
    "    df[\"season\"] = df.apply(get_season_string, axis=1)\n",
    "    # ------------------------------------------\n",
    "\n",
    "    # Sortierung logisch nach Datum\n",
    "    df = df.sort_values(by=\"Datum_Sortierbar\", ascending=True)\n",
    "    \n",
    "    # Aufräumen: Hilfsspalte löschen\n",
    "    df = df.drop(columns=[\"Datum_Sortierbar\"])\n",
    "        \n",
    "    # Spalten sortieren\n",
    "    cols = list(df.columns)\n",
    "    meta_cols = [\"Sendungstitel\", \"season\", \"Staffel\", \"Folge\", \"FolgenNr\", \"Publikationsdatum\", \"Dauer\", \"Infos\"] # season nach vorne geholt\n",
    "    gast_cols = [c for c in cols if c.startswith(\"Gast_\")]\n",
    "    gast_cols.sort(key=lambda x: int(x.split(\"_\")[1]))\n",
    "    \n",
    "    rest_cols = [c for c in cols if c not in meta_cols and c not in gast_cols]\n",
    "    \n",
    "    final_order = meta_cols + rest_cols + gast_cols\n",
    "    final_order = [c for c in final_order if c in df.columns]\n",
    "    \n",
    "    df = df[final_order]\n",
    "\n",
    "    # Wikidata Metadaten\n",
    "    df[\"instance_of\"] = 'Q21191270'\n",
    "    df[\"part_of_series\"] = 'Q1499182'\n",
    "    df[\"genre\"] = 'Q622812'\n",
    "    df[\"presenter\"] = 'Q43773'\n",
    "    df[\"original_broadcaster\"] = 'Q48989'\n",
    "    df[\"country_of_origin\"] = 'Q183'\n",
    "    df[\"original_language_of_film_or_TV_show\"] = 'Q188'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e76e54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seasons(episodes):\n",
    "    \"\"\"\n",
    "    Erstellt eine Übersicht der Staffeln basierend auf Jahren.\n",
    "    Staffel 1 beginnt 2008.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Zwischenspeicher: Key = Jahr, Value = Liste von Datum-Objekten\n",
    "    # Beispiel: { 2018: [datetime(2018,1,5), datetime(2018,1,6)...] }\n",
    "    years_data = {}\n",
    "\n",
    "    # Regex für das strikte Titelformat: \"Markus Lanz DD.MM.YYYY\"\n",
    "    # Sucht nach \"Markus Lanz \" gefolgt von Tag.Monat.Jahr\n",
    "    regex_title_strict = re.compile(r\"Markus Lanz \\s*\\d{2}\\.\\d{2}\\.\\d{4}\")\n",
    "    \n",
    "    # Regex um das Datum generell zu finden (dd.mm.yyyy)\n",
    "    regex_date = re.compile(r\"(\\d{2}\\.\\d{2}\\.\\d{4})\")\n",
    "\n",
    "    for episode_text in episodes:\n",
    "        if not episode_text:\n",
    "            continue\n",
    "            \n",
    "        # 1. Relevante Zeilen finden\n",
    "        # Wir suchen die Zeile, die mit \"Sendetitel\" beginnt, um das Format zu prüfen\n",
    "        lines = episode_text.splitlines()\n",
    "        title_line = \"\"\n",
    "        for line in lines:\n",
    "            if line.strip().startswith(\"Sendetitel\"):\n",
    "                title_line = line.strip()\n",
    "                break\n",
    "        \n",
    "        # Falls kein Sendetitel gefunden wurde, suchen wir im ganzen Text nach dem Datum\n",
    "        # (Fallback, falls Formatierung abweicht)\n",
    "        search_text = title_line if title_line else episode_text\n",
    "\n",
    "        # 2. Prüfen, ob Episode berücksichtigt werden soll\n",
    "        # Bedingung A: Titel hat Format \"Markus Lanz DD.MM.YYYY\"\n",
    "        condition_a = bool(regex_title_strict.search(title_line))\n",
    "        \n",
    "        # Bedingung B: Es gibt einen \"Staffel\" Eintrag im Text\n",
    "        condition_b = \"Staffel\" in episode_text\n",
    "        \n",
    "        if not (condition_a or condition_b):\n",
    "            continue\n",
    "\n",
    "        # 3. Datum extrahieren\n",
    "        # Wir bevorzugen das Datum aus dem Titel, sonst das erste Datum im Text\n",
    "        date_match = regex_date.search(title_line)\n",
    "        if not date_match:\n",
    "            # Fallback: Suche erstes Datum im gesamten Block (z.B. bei Info Sendedatum)\n",
    "            date_match = regex_date.search(episode_text)\n",
    "            \n",
    "        if date_match:\n",
    "            date_str = date_match.group(1)\n",
    "            try:\n",
    "                dt_obj = pd.to_datetime(date_str, format=\"%d.%m.%Y\")\n",
    "                year = dt_obj.year\n",
    "                \n",
    "                # Nur Jahre ab 2008 berücksichtigen (gemäß Logik Staffel 1 = 2008)\n",
    "                if year >= 2008:\n",
    "                    if year not in years_data:\n",
    "                        years_data[year] = []\n",
    "                    years_data[year].append(dt_obj)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # 4. DataFrame aus den gesammelten Daten bauen\n",
    "    season_rows = []\n",
    "    \n",
    "    # Sortierte Jahre durchgehen\n",
    "    for year in sorted(years_data.keys()):\n",
    "        dates = years_data[year]\n",
    "        \n",
    "        # Metriken berechnen\n",
    "        start_date = min(dates)\n",
    "        end_date = max(dates)\n",
    "        count = len(dates)\n",
    "        \n",
    "        # Staffelnummer berechnen (2008 -> 1, 2009 -> 2, etc.)\n",
    "        season_num = year - 2007\n",
    "        season_name = f\"Markus Lanz, Staffel {season_num}\"\n",
    "        \n",
    "        season_rows.append({\n",
    "            \"Staffel Name\": season_name,\n",
    "            \"start_time\": start_date, \n",
    "            \"end_time\": end_date,\n",
    "            \"Anzahl an Folgen\": count\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(season_rows)\n",
    "    \n",
    "    # Formatierung der Datumsspalten als String (DD.MM.YYYY) für schönere Ausgabe\n",
    "    if not df.empty:\n",
    "        df[\"start_time\"] = df[\"start_time\"].dt.strftime(\"%d.%m.%Y\")\n",
    "        df[\"end_time\"] = df[\"end_time\"].dt.strftime(\"%d.%m.%Y\")\n",
    "\n",
    "\n",
    "    df[\"instance_of\"] = 'Q3464665'\n",
    "    df[\"part_of_series\"] = 'Q1499182'\n",
    "    df[\"genre\"] = 'Q622812'\n",
    "    df[\"presenter\"] = 'Q43773'\n",
    "    df[\"original_broadcaster\"] = 'Q48989'\n",
    "    df[\"country_of_origin\"] = 'Q183'\n",
    "    df[\"original_language_of_film_or_TV_show\"] = 'Q188'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca939b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Extraktion von Markus Lanz_2008-2010.pdf...\n",
      "179 Folgen in Markus Lanz_2008-2010.pdf gefunden\n",
      "Starte Extraktion von Markus Lanz_2011-2015.pdf...\n",
      "638 Folgen in Markus Lanz_2011-2015.pdf gefunden\n",
      "Starte Extraktion von Markus Lanz_2016-2020.pdf...\n",
      "666 Folgen in Markus Lanz_2016-2020.pdf gefunden\n",
      "Starte Extraktion von Markus Lanz_2021-2024.pdf...\n",
      "555 Folgen in Markus Lanz_2021-2024.pdf gefunden\n"
     ]
    }
   ],
   "source": [
    "pdf_names = ['Markus Lanz_2008-2010.pdf', 'Markus Lanz_2011-2015.pdf', 'Markus Lanz_2016-2020.pdf', 'Markus Lanz_2021-2024.pdf']\n",
    "\n",
    "episode_strings = []\n",
    "\n",
    "for pdf_name in pdf_names:\n",
    "    path = f\"ZDF_Archiv/{pdf_name}\"\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            print(f\"Starte Extraktion von {pdf_name}...\")\n",
    "            episodes_from_pdf = build_text_list_from_pdf(path)\n",
    "            #text_files(episodes, filename=f\"textfiles/{pdf_name}_episodes.txt\")\n",
    "            for episode in reversed(episodes_from_pdf): \n",
    "                episode_strings.append(episode)\n",
    "            print(f\"{len(episodes_from_pdf)} Folgen in {pdf_name} gefunden\")\n",
    "        except Exception as e:\n",
    "            print(f\"Kritischer Fehler: {e}\")\n",
    "    else:\n",
    "        print(f\"Datei '{path}' nicht im Ordner gefunden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98260cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes found: 2036\n",
      "              Sendungstitel                  season Staffel Folge FolgenNr Publikationsdatum   Dauer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Infos        Gast_1         Gast_2             Gast_3       Gast_4         Gast_5 Gast_6 Gast_7 Gast_8 Gast_9 Gast_10 Gast_11 Gast_12 Gast_13 Gast_14 Gast_15 Gast_16 Gast_17 Gast_18 Gast_19 Gast_20 Gast_21 instance_of part_of_series    genre presenter original_broadcaster country_of_origin original_language_of_film_or_TV_show\n",
      "547  Markus Lanz 20.11.2013  Markus Lanz, Staffel 6       6   115      545        20.11.2013  075'44  23:33:39 - 00:49:23 075'44 Interview Markus Lanz mit Studiogästen Claudio ROTH (scheidende Vors. Bündnis 90 / Die Grünen), Tim MÄLZER (TV-Koch), Joko WINTERSCHEID (Moderator), Fritz EGNER (Moderator), Ingo POHLMANN (Sänger); Claudia Roth über ihren Umgang mit den emotionalen Belastungen beim Wahlkampf 2013, über ihre neue Position als Bundestagsvizepräsidentin, darüber, dass es eine große Herausforderung ist, Politik und Privatleben zu vereinbaren; über den Tod ihrer Mutter während des Wahlkampfs 2013; Tim Mälzer über die Anfänge seiner Sendung \"Schmeckt nicht, gibt's nicht!\", darüber, dass Fernsehmoderatoren, die wirkliche Kompetenz besitzen, durch ihren Erfolg in der Regel keine negative Persönlichkeitsentwicklung durchlaufen; seine langjährige Freundschaft zu Joko Winterscheid; Joko Winterscheid über seine Zeit als Redakteur der Kochsendung \"Schmeckt nicht, gibt's nicht!\", über seinen ersten Auftritt im Fernsehen neben Tim Mälzer in dessen Kochsendung, sein Kennenlernen mit seinem Kollegen Klaas Heufer-Umlauf, über seine Sendung \"Circus Halli Galli\"; darüber, dass er sich für die Sendung \"Joko gegen Klaas - Das Duell um die Welt\" seine Lippen zunähen ließ; über seien starke Höhenangst; Fritz Egner darüber, dass Radiomoderator sein erster Berufswunsch war; über sein aktuelles Buch \"Mein Leben zwischen Rhythmus und Blues\"; seine Zeit als Radiomoderator beim Sender Bayern 3, seine Bekanntschaft mit Thomas Gottschalk, seine Zeit als Moderator der Fernsehsendung \"Dingsda\"; Ingo Pohlmann über seine ehemalige Tätigkeit als Maurer, sein aktuelles Album \"Nix ohne Grund\", den Tod seines Bruders, der an einer Krebserkrankung starb (O-Ton).  Claudio ROTH     Tim MÄLZER  Joko WINTERSCHEID  Fritz EGNER  Ingo POHLMANN    NaN    NaN    NaN    NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   Q21191270       Q1499182  Q622812    Q43773               Q48989              Q183                                 Q188\n",
      "548  Markus Lanz 21.11.2013  Markus Lanz, Staffel 6       6   115      545        21.11.2013  076'10                                                                                         23:19:49 - 00:35:59 076'10 Interview Markus LANZ mit Studiogästen Stephen KING (Schriftsteller), Armin LASCHET (Vors. CDU Nordrhein-Westfalen), Werner SCHNEYDER (Kabarettist), Uschi GLAS (Schauspieler); Stephen King darüber, dass er gegenwärtig zum ersten Mal Deutschland besucht; darüber, dass er die deutsche Autobahn sehr beeindruckend findet; sein aktuelles Buch \"Doktor Sleep\"; darüber, dass er beim Schreiben gerne Heavy-Metal-Musik hört; über die Entstehung seines ersten Romans \"Carrie\", der Verlauf seiner Karriere als Schriftsteller, seine gelassene Einstellung zu Geld; seine Probleme mit Alkohol und Drogen in der Vergangenheit, über seinen schweren Autounfall; Armin Laschet über die bisherigen Kompromisse, die bei den aktuellen Koalitionsverhandlungen gefunden wurden; darüber, dass er die aktuellen Äußerungen von SPD-Politikern hinsichtlich einer Koalition mit der Linkspartei bei den nächsten Bundestagswahlen in Mitten der Gesprächsphase über eine große Koalition für absolut unangebracht hält; darüber, dass er eine Einführung des Mindestlohns für wahrscheinlich hält; Werner Schneyder über seine Freundschaft zu dem verstorbenen Kabarettisten Dieter Hildebrandt, sein schwieriges Verhältnis zu seinem Vater, seine Gedanken über Sterben und den Tod; Uschi Glas über ihren Karrieredurchbruch 1968 mit ihrer Rolle in dem Spielfilm \"Zur Sache, Schätzen\", darüber, dass sie sich eine Autobahnmaut für Ausländer wünscht, über ihre Rolle als verzweifelte Lehrerin mi aktuellen Kinofilm \"Fack Ju Göhte\", über ihr schwieriges Verhältnis zu ihrem Vater (O-Ton).  Stephen KING  Armin LASCHET   Werner SCHNEYDER   Uschi GLAS            NaN    NaN    NaN    NaN    NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   Q21191270       Q1499182  Q622812    Q43773               Q48989              Q183                                 Q188\n"
     ]
    }
   ],
   "source": [
    "episode_strings = clean_episodes(episode_strings)\n",
    "\n",
    "print(f\"Episodes found: {len(episode_strings)}\")\n",
    "\n",
    "\n",
    "persondf = extract_persons(episode_strings)\n",
    "persondf.to_csv(f\"person/Personen.csv\", index=False)\n",
    "\n",
    "episodesdf = extract_episodes(episode_strings)\n",
    "duplicates =    episodesdf[\n",
    "                episodesdf['FolgenNr'].notna() &\n",
    "                episodesdf.duplicated(subset=['FolgenNr'], keep=False)\n",
    "]\n",
    "print(duplicates.to_string())\n",
    "\n",
    "episodesdf.to_csv(f\"episodes/Episoden.csv\", index=False)\n",
    "\n",
    "seasonsdf = extract_seasons(episode_strings)\n",
    "seasonsdf.to_csv(f\"seasons/Staffeln.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0705963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
